{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c2db3c-570a-4520-97f9-e99b7cce1377",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca2677e-6dbf-49cb-94cf-55ab34553123",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# specify substep parameters for interactive run\n",
    "# this cell will be replaced during job run with the parameters from json within params subfolder\n",
    "substep_params={\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04468dc-4a2c-4ac0-8a9c-b36dc26f9a22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load pipeline and step parameters - do not edit\n",
    "from sinara.substep import get_pipeline_params, get_step_params\n",
    "pipeline_params = get_pipeline_params(pprint=True)\n",
    "step_params = get_step_params(pprint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa0a075-eca9-4b7a-ab12-457a84f5dbb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define substep interface\n",
    "from sinara.substep import NotebookSubstep, ENV_NAME, PIPELINE_NAME, ZONE_NAME, STEP_NAME, RUN_ID, ENTITY_NAME, ENTITY_PATH, SUBSTEP_NAME\n",
    "\n",
    "substep = NotebookSubstep(pipeline_params, step_params, substep_params)\n",
    "\n",
    "substep.interface(\n",
    "    inputs =\n",
    "    [ \n",
    "      {PIPELINE_NAME: \"face_detect_rest\", STEP_NAME: \"model_pack\", ENTITY_NAME: \"bento_service\"}, # bentoservice file from pack step of pipeline face_detect_rest \n",
    "      {PIPELINE_NAME: \"facemask_classification_rest\", STEP_NAME: \"model_pack\", ENTITY_NAME: \"bento_service\"} # bentoservice file from pack step of facemask_classification_rest\n",
    "    ]\n",
    "    \n",
    ")\n",
    "\n",
    "substep.print_interface_info()\n",
    "substep.exit_in_visualize_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d85b790-e2cd-4024-911c-fa6699f6951d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os.path as osp\n",
    "from pathlib import Path\n",
    "import json\n",
    "import atexit\n",
    "import requests\n",
    "import base64\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd68621e-9865-46c1-b083-1a66e87b59a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run spark\n",
    "from sinara.spark import SinaraSpark\n",
    "\n",
    "spark = SinaraSpark.run_session(0)\n",
    "SinaraSpark.ui_url()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21e1611-39ad-4a0c-8d16-376117080310",
   "metadata": {},
   "source": [
    "### Loading REST Bentoservice "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccfb4f9-f590-46d4-b705-8b6d47737591",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sinara.bentoml import load_bentoservice\n",
    "\n",
    "# load bentoservise\n",
    "inputs_face_detect= substep.inputs(step_name = \"model_pack\", pipeline_name = \"face_detect_rest\")\n",
    "inputs_facemask_classification= substep.inputs(step_name = \"model_pack\", pipeline_name = \"facemask_classification_rest\")\n",
    "\n",
    "face_detect_service = load_bentoservice(inputs_face_detect.bento_service, \n",
    "                                        bentoservice_name=\"face_detect_service\")\n",
    "facemask_classification_service = load_bentoservice(inputs_facemask_classification.bento_service,\n",
    "                                                    bentoservice_name=\"facemask_classification_service\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ca4f76-74cb-40af-8131-4f785a1b48ce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "face_detect_service.service_version()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a128e2-3f73-4101-b168-5a1c18605e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "facemask_classification_service.service_version()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a447cdc-9d4d-4933-aace-376278bb948a",
   "metadata": {},
   "source": [
    "### Start Bentoservice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57aa41ec-80d9-4d2f-a0fd-5fa4c68f010a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sinara.bentoml import start_dev_bentoservice, stop_dev_bentoservice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2e67ed-e62f-457e-b70d-24c6c782f505",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture cap --no-stderr\n",
    "# Stop a dev model server if running\n",
    "stop_dev_bentoservice(face_detect_service)\n",
    "stop_dev_bentoservice(facemask_classification_service)\n",
    "\n",
    "# Start a dev model server to test out the API endpoint locally\n",
    "start_dev_bentoservice(face_detect_service, use_popen=True, debug=False, port = 5001)\n",
    "start_dev_bentoservice(facemask_classification_service, use_popen=True, debug=False, port = 5002)\n",
    "_=atexit.register(stop_dev_bentoservice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf85a82c-608a-42d8-9dd8-30a3f5adca38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# example REST API get service_version face_detect_service\n",
    "service_version = requests.post(\"http://127.0.0.1:5001/service_version\", json={}).json()\n",
    "print(f\"service_version face_detect_service: {service_version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf79f29-fff2-4a24-be43-ad3053001076",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example REST API get service_version facemask_classification_service\n",
    "service_version = requests.post(\"http://127.0.0.1:5002/service_version\", json={}).json()\n",
    "print(f\"service_version facemask_classification_service: {service_version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "851c5eb3-46e3-42ee-8b8b-dfcc54bdad54",
   "metadata": {},
   "source": [
    "### Predict test_data by ensemble face_detect_service and facemask_classification_service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4204b8ad-1c48-4d73-a0a3-960f3e16c41e",
   "metadata": {},
   "source": [
    "#### Get test_data from face_detect_service\n",
    "(test image, which should be stored in the bento service, and can be obtained using the test_data method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9df9022-423b-4c70-8a36-31c3a0b47aea",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_data_api_endpoint = f'http://127.0.0.1:5001/test_data'\n",
    "test_data_response = requests.request(\"POST\", test_data_api_endpoint, json={})\n",
    "\n",
    "content = test_data_response.json()\n",
    "encoded_test_data = content['b64']\n",
    "test_data = base64.b64decode(encoded_test_data)\n",
    "\n",
    "image_array = np.frombuffer(test_data, np.int8)\n",
    "numpy_test_data = cv2.imdecode(image_array, cv2.IMREAD_COLOR)\n",
    "numpy_test_data = cv2.cvtColor(numpy_test_data, cv2.COLOR_BGR2RGB )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f52f226-7be2-49b0-9b5d-370a2c991baf",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Predict test_data by face_detect_service\n",
    "(sending test image test_data to predict method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c232aa6-ede6-4359-9676-3ad2ef9a4509",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "predict_face_detect_response = requests.post('http://127.0.0.1:5001/predict', \n",
    "                                             headers={'Content-Type': 'application/octet-stream'}, \n",
    "                                             data=cv2.imencode('.png', numpy_test_data)[1].tobytes())\n",
    "predict_face_detect_result = predict_face_detect_response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28545d54-554c-4810-8377-3f80262fe800",
   "metadata": {},
   "source": [
    "### Predict every crop image of predicted objects by facemask_classification_service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455fcd26-945a-4607-bb21-655ac7945439",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_result = predict_face_detect_result.copy()\n",
    "predict_result[\"annotations\"] = []\n",
    "\n",
    "for ann_obj in predict_face_detect_result[\"annotations\"]:\n",
    "    score = ann_obj[\"score\"]\n",
    "    if score < 0.5:\n",
    "        continue\n",
    "    id_obj = ann_obj[\"id\"]\n",
    "    bbox = ann_obj[\"bbox\"]  # coco format: xywh (x_top_left, y_top_left, w_object, h_object)\n",
    "    x_tl, y_tl, w_obj, h_obj  = bbox\n",
    "\n",
    "    # get crop image of face in test_image\n",
    "    crop_image_obj = numpy_test_data[y_tl:y_tl+h_obj, x_tl:x_tl+w_obj]\n",
    "\n",
    "    # predict facemask_classification_service\n",
    "    predict_facemask_classification_response = requests.post(\"http://127.0.0.1:5002/predict\", \n",
    "                                                             headers={'Content-Type': 'application/octet-stream'}, \n",
    "                                                             data=cv2.imencode('.png', crop_image_obj)[1].tobytes())\n",
    "    predict_facemask_classification_result = predict_facemask_classification_response.json()\n",
    "    face_class = predict_facemask_classification_result[\"class_names\"][0]\n",
    "    face_class_scores = predict_facemask_classification_result[\"class_scores\"]\n",
    "    attribute_obj = {\"face_class\": face_class,\n",
    "                     \"face_class_scores\": face_class_scores}\n",
    "    ann_obj.update({\"attribute\": attribute_obj})\n",
    "    predict_result[\"annotations\"].append(ann_obj.copy())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232349f0-6155-49f6-96dc-81053a52e1f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Stop spark\n",
    "SinaraSpark.stop_session()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
